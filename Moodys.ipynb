{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cmp_to_key\n",
    "import itertools\n",
    "\n",
    "\n",
    "#custom compare function to sort list containing words in one column\n",
    "def compare(word1,word2):\n",
    "    y1_value = int(word1[3])\n",
    "    x1_value_l = int(word1[1])\n",
    "    y2_value = int(word2[3])\n",
    "    x2_value_l = int(word2[1])\n",
    "    \n",
    "    #arbitrary value to decide if words are on same line\n",
    "    if(abs(y1_value-y2_value) < 80 ):\n",
    "        return x1_value_l - x2_value_l\n",
    "    \n",
    "    else:\n",
    "        return y1_value-y2_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###for .day only\n",
    "prev_y = 0\n",
    "prev_x = 0\n",
    "num_cols= 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_bucket(row):\n",
    "    global prev_y\n",
    "    global num_cols\n",
    "    global prev_x\n",
    "    y_value = int(row[3])\n",
    "    x_value_l = int(row[1])\n",
    "    x_value_r = int(row[2])\n",
    "    word = row[-2]\n",
    "    res = ''\n",
    "    if(abs(y_value-prev_y) < 80 ):\n",
    "        if(abs(x_value_l-prev_x) < 300):\n",
    "            res = word\n",
    "        else:\n",
    "            res = '\\t' + word\n",
    "            \n",
    "    else:\n",
    "        res= '\\n'+word\n",
    "    \n",
    "    prev_y = y_value\n",
    "    prev_x = x_value_r\n",
    "    return res\n",
    "        \n",
    "            \n",
    "        \n",
    "def organize_day(images):\n",
    "    x = 0\n",
    "    #create an array of dictionaries, each element the text from given brightness level\n",
    "    brightness_level = [{} for sub in range(200)]\n",
    "    for i in range(len(images)): \n",
    "        num_cols = 1\n",
    "        image = images[i]\n",
    "        #if image contains no information, skip to next iteration\n",
    "\n",
    "        if image == '':\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                words = image.strip()\n",
    "                words = words.split('\\n')\n",
    "                dfWords = pd.DataFrame([sub.split(\",\") for sub in words])\n",
    "             # find delta y between words to find new column markers\n",
    "                dfWords = dfWords.astype({3:'int'})\n",
    "                dfWords['yDif'] = dfWords[3].diff()\n",
    "                col_breaks = dfWords.loc[dfWords['yDif'] < -9000].index.values\n",
    "                    \n",
    "                #if there are > 1 column, take each column, and sort it\n",
    "                res = []\n",
    "                if(len(col_breaks)>0):\n",
    "                    prev = 0\n",
    "                    for c in col_breaks:\n",
    "                        holder = []\n",
    "                        col = dfWords.iloc[prev:c].values.tolist()\n",
    "                        colDF = pd.DataFrame(sorted(col, key=cmp_to_key(compare)))\n",
    "                        colDF.apply(lambda x: holder.append(find_bucket( x.to_list()))  , axis = 1)\n",
    "                        res.append(holder)\n",
    "                        prev = c\n",
    "\n",
    "                    holder = []\n",
    "                    col = dfWords.iloc[col_breaks[-1]:].values.tolist()\n",
    "                    colDF = pd.DataFrame(sorted(col, key=cmp_to_key(compare)))\n",
    "                    colDF.apply(lambda x: holder.append(find_bucket( x.to_list()))  , axis = 1)\n",
    "                    res.append(holder)\n",
    "                else:\n",
    "                    dfWords.apply(lambda x: res.append(find_bucket( x.to_list()))  , axis = 1)\n",
    "                brightness_level[x] = res\n",
    "                x+=1\n",
    "\n",
    "            except Exception as e:\n",
    "                z = 1\n",
    "\n",
    "                \n",
    "    return brightness_level\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####for .dat files\n",
    "\n",
    "prev_y = 0\n",
    "prev_x = 0\n",
    "\n",
    "\n",
    "def organize_dat(images):\n",
    "    x = 0\n",
    "    #create an array of dictionaries, each element the text from given brightness level\n",
    "    brightness_level = [{} for sub in range(200)]\n",
    "    for i in range(len(images)): \n",
    "        num_cols = 1\n",
    "        image = images[i]\n",
    "        #if image contains no information, skip to next iteration\n",
    "\n",
    "        if image == '':\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "            #split current image info with line boundaries and word boundaries\n",
    "            info = re.split('[\\/[A-Za-z0-9-.]+\\/*\\.day', image)\n",
    "            try:\n",
    "                lines = info[0].strip()\n",
    "                words = info[1].strip()\n",
    "                if(lines != ''):\n",
    "                    num_lines = lines.count('\\n')+1\n",
    "                    lines = lines.split('\\n')\n",
    "                    words = words.split('\\n')\n",
    "                    words = [sub.split(\",\") for sub in words]\n",
    "                    dfWords = pd.DataFrame(words)\n",
    "                    \n",
    "                    # find delta y between words to find new column markers\n",
    "                    dfWords = dfWords.astype({3:'int'})\n",
    "                    dfWords['yDif'] = dfWords[3].diff()\n",
    "                    col_breaks = dfWords.loc[dfWords['yDif'] < -9000].index.values\n",
    "                    \n",
    "                    #if there are > 1 column, take each column, and sort it\n",
    "                    res = []\n",
    "                    if(len(col_breaks)>0):\n",
    "                        prev = 0\n",
    "                        for c in col_breaks:\n",
    "                            holder = []\n",
    "                            col = dfWords.iloc[prev:c].values.tolist()\n",
    "                            colDF = pd.DataFrame(sorted(col, key=cmp_to_key(compare)))\n",
    "                            colDF.apply(lambda x: holder.append(find_bucket( x.to_list()))  , axis = 1)\n",
    "                            res.append(holder)\n",
    "                            prev = c\n",
    "\n",
    "                        holder = []\n",
    "                        col = dfWords.iloc[col_breaks[-1]:].values.tolist()\n",
    "                        colDF = pd.DataFrame(sorted(col, key=cmp_to_key(compare)))\n",
    "                        colDF.apply(lambda x: holder.append(find_bucket( x.to_list()))  , axis = 1)\n",
    "                        res.append(holder)\n",
    "                    else:\n",
    "                        dfWords.apply(lambda x: res.append(find_bucket( x.to_list()))  , axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "                    #go through word df and append word data to bucket it is closest to\n",
    "                    brightness_level[x] = res\n",
    "                    x+=1\n",
    "\n",
    "            except Exception as e:\n",
    "                z = 1\n",
    "                \n",
    "    return brightness_level\n",
    "\n",
    "                \n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def assemble(brightness_level):\n",
    "    res = []\n",
    "    term_dict = {}\n",
    "    \n",
    "    #contents of one page\n",
    "    for count, blocks in enumerate(brightness_level):\n",
    "        blob_set = set()\n",
    "        if(blocks != None):\n",
    "            try:\n",
    "                cols = []\n",
    "                full_text = []\n",
    "                \n",
    "                #if multiple columns\n",
    "                if(len(blocks) < 10):\n",
    "                    for col in blocks : \n",
    "                        cols.append(' '.join(col))\n",
    "                        full_text.extend(col)\n",
    "\n",
    "                    blob = '\\n\\n'.join(cols)\n",
    "                else:\n",
    "                    blob = ' '.join(blocks)\n",
    "                    \n",
    "                #counts bigrams in blob and adds count to bigram dictionary\n",
    "                for x in range(len(full_text)-1):\n",
    "                    ngram = full_text[x]+full_text[x+1]\n",
    "                    blob_set.add(ngram)\n",
    "                    if ngram in term_dict:\n",
    "                        term_dict[ngram] +=1\n",
    "                    else:\n",
    "                        term_dict[ngram] = 1\n",
    "                \n",
    "        \n",
    "                res.append((blob,blob_set))\n",
    "            except Exception as e:\n",
    "                z= 1\n",
    "                \n",
    "    #returns put together text blob and also its word dictionary\n",
    "    return term_dict, res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#finds text blob that has highest score of bigrams \n",
    "def find_opt(res, term_dict):\n",
    "    total = 0\n",
    "    optimum = ''\n",
    "    opt_brightness = -1\n",
    "    for brightness,blocks in enumerate(res):\n",
    "        blob_total = 0\n",
    "        blob_set = blocks[1]\n",
    "        blob = blocks[0]\n",
    "        for ngram in blob_set:\n",
    "            blob_total += term_dict[ngram]\n",
    "        if(blob_total > total):\n",
    "            total = blob_total\n",
    "            optimum = blob\n",
    "            opt_brightness = brightness\n",
    "\n",
    "    return opt_brightness,optimum\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#parameter of all capital strings in page, throws out ones that do not contain company endings\n",
    "#returns company names\n",
    "def find_caps(text):\n",
    "    company_words = {' INC ', ' CO ', ' CORP ', ' LTD ', 'PRODUCTIONS', 'LLC'}\n",
    "    all_caps = re.findall(r'((?:[A-Z]{2,} *){2,})', optimum)\n",
    "    companies = set()\n",
    "\n",
    "    for w in company_words:\n",
    "        for name in all_caps:\n",
    "            if(w in name):\n",
    "                companies.add(name)\n",
    "                continue\n",
    "                \n",
    "    return list(companies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def sort_companies(comp):\n",
    "    return comp(0)\n",
    "    \n",
    "\n",
    "path = '/scratch/summit/diga9728/Moodys/Industrials/OCRrun1941/133/OCR.micro.19410015-0028.zay'\n",
    "\n",
    "#get directory and parse all pages in directory\n",
    "directory = r'/scratch/summit/diga9728/Moodys/Industrials/OCRrun1929/136'\n",
    "\n",
    "#dictionary to store company info\n",
    "comp_dict = {}\n",
    "\n",
    "for entry in os.scandir(directory):\n",
    "    path = entry.path\n",
    "    #open page file and split images at lines containing .day\n",
    "    file = open(path, 'r').read()\n",
    "\n",
    "    #some files have line info, so we have two different methods to read depending on file contents\n",
    "    if(len(re.findall('[\\/[A-Za-z0-9-._]+\\/*\\.dat', file)) > 1):\n",
    "        images = re.split('[\\/[A-Za-z0-9-._]+\\/*\\.dat', file)\n",
    "        brightness_levels = organize_dat(images)\n",
    "    else:\n",
    "        images = re.split('[\\/[A-Za-z0-9-._]+\\/*\\.day', file)\n",
    "        brightness_levels = organize_day(images)\n",
    "\n",
    "    #get all ngrams from the 99 iterations and each text blob from the 99 iterations\n",
    "    term_dict,res = assemble(brightness_levels)\n",
    "    \n",
    "    #find optimum brightness and correlating blob\n",
    "    opt_brightness,optimum = find_opt(res,term_dict)\n",
    "    \n",
    "    #check to see if print looks like its right\n",
    "    #print(optimum)\n",
    "    \n",
    "    #find companies by words that are in all caps\n",
    "    companies = find_caps(optimum)\n",
    "    \n",
    "    #get indices of company names in text string\n",
    "    companies = sorted([(optimum.find(x),x) for x in companies])\n",
    "    companies.append((len(optimum),'holder'))\n",
    "    \n",
    "    #try to parse for history and officers section of multiple companies on page\n",
    "    if(len(companies) > 1):\n",
    "        for x in range(len(companies)-1):\n",
    "            first = companies[x]\n",
    "            second = companies[x+1]\n",
    "            company_text = optimum[first[0]: second[0]]\n",
    "            history = company_text[company_text.find('History'):company_text.find('Officers')]\n",
    "            officers = company_text[company_text.find('Officers'):company_text.find('Directors')]\n",
    "            comp_dict[first[1].strip()] = {'history': history, 'officers':officers}\n",
    "            \n",
    "    #only one company found on page\n",
    "    elif(len(companies) == 2):\n",
    "        first = companies[0]\n",
    "        comp_dict[first[1]] = optimum[first[0]: len(optimum)]\n",
    "        \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(comp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
